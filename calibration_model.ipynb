{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as tr\n",
    "import torchvision.transforms.v2.functional as trv2\n",
    "from torchvision.transforms import RandomRotation\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import hickle\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import ast\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Global Variables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = \"/home/tyler/Documents/School Material/Current Semester/Research Team/Code/PinDataCalibrateTrain/data.csv\"\n",
    "val_csv = \"/home/tyler/Documents/School Material/Current Semester/Research Team/Code/PinDataCalibrateVal/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"./best_model/best_calibration_weights.pt\"\n",
    "last_epoch_model_path = \"./best_model/last_calibration_weights.pt\"\n",
    "best_loss_path = \"./best_model/calibration_loss.txt\"\n",
    "os.makedirs(\"./best_model/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_inputs = 5\n",
    "num_of_outputs = 6\n",
    "num_of_frames = 101\n",
    "\n",
    "hidden_size = 256\n",
    "num_of_rnn_layers = 1\n",
    "embedding_size = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECTION_SIZE_HEIGHT = 80\n",
    "SECTION_SIZE_WIDTH = 80\n",
    "FONT_SIZE = 0.7\n",
    "THICKNESS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LOSS_KEY = \"Training Loss\"\n",
    "TRAIN_ACCURACY_KEY = \"Training Accuracy\"\n",
    "\n",
    "VAL_LOSS_KEY = \"Validation Loss\"\n",
    "VAL_ACCURACY_KEY = \"Validation Accuracy\"\n",
    "\n",
    "TEST_LOSS_KEY = \"Testing Loss\"\n",
    "TEST_ACCURACY_KEY = \"Testing Accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Aux Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_loss(current_loss: float, model):\n",
    "    \n",
    "    try:\n",
    "        file = open(best_loss_path, \"r+\")\n",
    "    except:\n",
    "        file = open(best_loss_path, \"w+\")\n",
    "        file.write(\"100\")\n",
    "        file.close()\n",
    "        get_best_loss(current_loss, model)\n",
    "        return\n",
    "        \n",
    "    line = file.readline()\n",
    "    best_loss = float(line.replace(\"\\n\", \"\"))\n",
    "\n",
    "    got_new_loss = False\n",
    "\n",
    "    if current_loss < best_loss:\n",
    "        file.seek(0)\n",
    "        file.write(str(current_loss))\n",
    "        file.truncate()\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"New best loss!\")\n",
    "        got_new_loss = True\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    torch.save(model.state_dict(), last_epoch_model_path)\n",
    "\n",
    "    return got_new_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrects_and_size(pred, y):\n",
    "    \n",
    "    pred = torch.argmax(pred, dim=0)\n",
    "    y = torch.argmax(y, dim=0)\n",
    "    corrects = torch.eq(pred,y).int()\n",
    "    correct = corrects.sum().item()\n",
    "    size = corrects.numel()\n",
    "\n",
    "    return correct, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line(list: list):\n",
    "    line = [str(x) for x in list]\n",
    "    line = ','.join(line)\n",
    "    line += \"\\n\"\n",
    "    line = line.replace(\"]\", \"\").replace(\"[\", \"\").replace(\" \", \"\")\n",
    "\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset):\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = int(0.1 * len(dataset))\n",
    "    test_size = len(dataset) - (train_size + val_size) \n",
    "    train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, test_size, val_size])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_and_save_graph(metrics:dict, ylabel:str,  key_one:str, key_two:str=None):\n",
    "    \n",
    "    metric_one = metrics[key_one]\n",
    "    metric_two = metrics[key_two]\n",
    "\n",
    "    plt.plot([i + 1 for i in range(len(metric_one))] ,metric_one)\n",
    "    plt.plot([i + 1 for i in range(len(metric_two))] ,metric_two)\n",
    "\n",
    "    if key_two is not None:\n",
    "\n",
    "        title = f'{key_one} and {key_two} vs Epoch'\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.title(title)\n",
    "        plt.legend([key_one, key_two])\n",
    "\n",
    "    else:\n",
    "        title = f'{key_one} vs Epoch'\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.title(title)\n",
    "        plt.legend([key_one])\n",
    "    \n",
    "    plt.grid()\n",
    "\n",
    "    os.makedirs(\"./Figures/\", exist_ok=True) \n",
    "    plt.savefig(f\"./Figures/{title}_{int(time.time())}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_metrics(*args):\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    for key in args:\n",
    "        metrics[key] = []\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_grid_lines(img):\n",
    "    for i in range(0, len(img), SECTION_SIZE_HEIGHT):\n",
    "        for j in range(0, len(img[i])):\n",
    "            img[i,j] = (0,0,255)\n",
    "            \n",
    "\n",
    "    for i in range(0, len(img)):\n",
    "        for j in range(0, len(img[i]), SECTION_SIZE_WIDTH):\n",
    "            img[i,j] = (0,0,255)\n",
    "        \n",
    "    \n",
    "    col = 0\n",
    "    for i in range(0, len(img), SECTION_SIZE_WIDTH):\n",
    "\n",
    "        row = 0\n",
    "        for j in range(0, len(img[i]), SECTION_SIZE_HEIGHT):\n",
    "            \n",
    "            text = f\"{row}, {col}\"\n",
    "            cv2.putText(img,text, (i, j + 15), cv2.FONT_HERSHEY_SIMPLEX, FONT_SIZE, (255,0,0), thickness=THICKNESS)\n",
    "            row += 1\n",
    "\n",
    "        col += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(src_dir: str):\n",
    "    file_names = [f for f in listdir(src_dir) if isfile(join(src_dir, f))]\n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_augmentation = A.Compose([\n",
    "    A.GaussianBlur((9,21)),\n",
    "    A.ColorJitter(),\n",
    "    A.GaussNoise()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_normalize = A.Compose([\n",
    "    A.Normalize(always_apply=True),\n",
    "    A.ToFloat(always_apply=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_resize= A.Compose([\n",
    "    A.LongestMaxSize(192, always_apply=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Custom Dataset Init</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, csv):\n",
    "        df = pd.read_csv(csv, header=0)\n",
    "        self.df = df\n",
    "        self.predictors = df[\"file_name\"].to_numpy()\n",
    "        self.cls = df[\"pin\"].to_numpy()\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.__len__():\n",
    "            raise StopIteration\n",
    "        \n",
    "        file_name = self.predictors[idx]\n",
    "        target = self.cls[idx]\n",
    "        \n",
    "        predictors = cv2.imread(file_name)\n",
    "        predictors = transform_resize(image=predictors)[\"image\"]\n",
    "        predictors = transform_augmentation(image=predictors)[\"image\"]\n",
    "        # add_grid_lines(predictors)\n",
    "        predictors = transform_normalize(image=predictors)[\"image\"]\n",
    "        predictors = torch.tensor(predictors, device=device).permute([2,0,1])\n",
    "\n",
    "        target = [int(x) for x in target.split(\",\")]\n",
    "\n",
    "        target_1 = torch.tensor([0,0,0,0,0,0], device=device).float()\n",
    "        target_2 = torch.tensor([0,0,0,0,0,0], device=device).float()\n",
    "\n",
    "        target_1[target[0]] = 1\n",
    "        target_2[target[1]] = 1\n",
    "\n",
    "        target = torch.vstack([target_1, target_2])\n",
    "\n",
    "        # target = torch.tensor(target, device=device) / 5\n",
    "\n",
    "        return (predictors, target)\n",
    "        # return (predictors, target, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataSet(train_csv)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "val_dataset = CustomDataSet(val_csv)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, X in enumerate(custom_dataset):\n",
    "#     print(f'i : {i} X: {X}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (predictors, target) in enumerate(train_dataset):\n",
    "#     print(f'i : {i} input_file: {predictors}{predictors.shape}')\n",
    "#     print(f'i : {i} target: {target}{target.shape}')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Neural Net Classes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlockDown(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlockUp(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Upsample(2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipConnection(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv2d = nn.Conv2d(in_channels, out_channels, 1, padding=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv2d(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(in_features, out_features, 3, padding=1),\n",
    "            nn.ELU()\n",
    "        )\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(out_features, out_features, 3, padding=1),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "        self.skip1 = SkipConnection(in_features, out_features)\n",
    "        self.pool = nn.MaxPool2d((2,2))\n",
    "        \n",
    "\n",
    "    def forward(self, x1):\n",
    "\n",
    "        x2 = self.cnn1(x1)\n",
    "        x2 = self.cnn2(x2)\n",
    "\n",
    "        x1 = self.skip1(x1)\n",
    "\n",
    "        x2 += x1\n",
    "\n",
    "        x2 = F.elu(x2)\n",
    "        x2 = self.pool(x2)\n",
    "\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dense = nn.Sequential(nn.Linear(in_features, out_features),\n",
    "                                    nn.LayerNorm(out_features),\n",
    "                                    nn.ELU())\n",
    "        \n",
    "    def forward(self, x1):\n",
    "        return self.dense(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        base = 1024\n",
    "\n",
    "        self.start = nn.Sequential(\n",
    "            nn.Conv2d(3, base // 32, 7, padding=3),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d((2,2))\n",
    "        )\n",
    "        \n",
    "        self.block1 = ConvBlock(base // 32, base // 16)\n",
    "        self.block2 = ConvBlock(base // 16, base // 8)\n",
    "        self.block3 = ConvBlock(base // 8, base // 4)\n",
    "        self.block4 = ConvBlock(base // 4, base // 2)\n",
    "        self.block5 = ConvBlock(base // 2, base // 2)\n",
    "        self.block6 = ConvBlock(base // 2, base)\n",
    "        self.last = nn.Conv2d(base, base, 1, padding=0)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1_1 = nn.Linear(base, 128)\n",
    "        self.out1 = nn.Linear(128, num_of_outputs)\n",
    "\n",
    "        self.fc1_2 = nn.Linear(base, 128)\n",
    "        self.out2 = nn.Linear(128, num_of_outputs)\n",
    "        \n",
    "    def forward(self, x1):\n",
    "        \n",
    "        x1 = self.start(x1)\n",
    "        x1 = self.block1(x1) \n",
    "        x1 = self.block2(x1) \n",
    "        x1 = self.block3(x1) \n",
    "        x1 = self.block4(x1) \n",
    "        x1 = self.block5(x1) \n",
    "        x1 = self.block6(x1) \n",
    "    \n",
    "        x1 = self.last(x1)\n",
    "        x1 = self.flatten(x1)\n",
    "    \n",
    "        o1 = self.fc1_1(x1)\n",
    "        o1 = F.elu(o1)\n",
    "        o1 = self.out1(o1)\n",
    "\n",
    "        o2 = self.fc1_2(x1)\n",
    "        o2 = F.elu(o2)\n",
    "        o2 = self.out2(o2)\n",
    "\n",
    "        return torch.vstack([o1.unsqueeze(0), o2.unsqueeze(0)]).permute([1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NeuralNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         base = 1024\n",
    "\n",
    "#         self.start = nn.Sequential(\n",
    "#             nn.Conv2d(3, base // 32, 7, padding=3),\n",
    "#             nn.ELU(),\n",
    "#             nn.MaxPool2d((2,2))\n",
    "#         )\n",
    "        \n",
    "#         self.block1 = ConvBlock(base // 32, base // 16)\n",
    "#         self.block2 = ConvBlock(base // 16, base // 8)\n",
    "#         self.block3 = ConvBlock(base // 8, base // 4)\n",
    "#         self.block4 = ConvBlock(base // 4, base // 2)\n",
    "#         self.block5 = ConvBlock(base // 2, base // 2)\n",
    "#         self.block6 = ConvBlock(base // 2, base)\n",
    "        \n",
    "#         self.last = nn.Conv2d(base, base, 1, padding=0)\n",
    "#         self.flatten = nn.Flatten()\n",
    "\n",
    "        # self.out = nn.Sequential(\n",
    "        #     DenseLayer(base, 128),\n",
    "        #     DenseLayer(128, 64),\n",
    "        #     nn.Linear(64, num_of_outputs)\n",
    "        # )\n",
    "        \n",
    "#     def forward(self, x1):\n",
    "        \n",
    "#         x1 = self.start(x1)\n",
    "#         x1 = self.block1(x1) \n",
    "#         x1 = self.block2(x1) \n",
    "#         x1 = self.block3(x1) \n",
    "#         x1 = self.block4(x1) \n",
    "#         x1 = self.block5(x1) \n",
    "#         x1 = self.block6(x1) \n",
    "    \n",
    "#         x1 = self.last(x1)\n",
    "#         x1 = self.flatten(x1)\n",
    "    \n",
    "#         x1 = self.out(x1)\n",
    "\n",
    "#         return x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model Init</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet().to(device)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total Params: {pytorch_total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion1 = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(list(model.parameters()), lr=0.00001)\n",
    "metrics = init_metrics(TRAIN_LOSS_KEY, TRAIN_ACCURACY_KEY, VAL_LOSS_KEY, VAL_ACCURACY_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train and Test Init</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(dataloader, optimizer, is_training: bool, is_classification: bool):\n",
    "\n",
    "    if is_training:\n",
    "        model.train()\n",
    "        mode_str = \"Train\"\n",
    "        loss_history = metrics[TRAIN_LOSS_KEY]\n",
    "        accuracy_history = metrics[TRAIN_ACCURACY_KEY]\n",
    "\n",
    "    else:\n",
    "        model.eval()\n",
    "        mode_str = \"Val\"\n",
    "        loss_history = metrics[VAL_LOSS_KEY]\n",
    "        accuracy_history = metrics[VAL_ACCURACY_KEY]\n",
    "    \n",
    "    size = 0\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    loss, loss_num, correct = 0, 0, 0\n",
    "    correct_makes, correct_misses = 0, 0\n",
    "    incorrect_on_class, incorrect_off_class = 0, 0\n",
    "\n",
    "    \n",
    "    \n",
    "    for X, y in dataloader:\n",
    "\n",
    "        pred = model(X)\n",
    "\n",
    "        loss = criterion1(pred, y)\n",
    "\n",
    "        loss_num += loss.item()\n",
    "\n",
    "        if is_training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if is_classification:\n",
    "\n",
    "            corrects, sizes = get_corrects_and_size(pred, y)\n",
    "\n",
    "            correct += corrects\n",
    "            size += sizes\n",
    "\n",
    "    loss_num /= num_batches\n",
    "    loss_history.append(loss_num)\n",
    "\n",
    "    # Calculate Classification Metrics\n",
    "    if is_classification:\n",
    "\n",
    "        correct /= size\n",
    "        accuracy = 100*correct\n",
    "        accuracy_history.append(accuracy)\n",
    "        print(f\"{mode_str} Accuracy: {(accuracy):>0.3f}\")\n",
    "\n",
    "    print(f\"{mode_str} Loss: {loss_num:>12f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(start, t, t_with_best_loss, best_loss):\n",
    "    train_loss_hist = metrics[TRAIN_LOSS_KEY]\n",
    "    val_loss_hist = metrics[VAL_LOSS_KEY]\n",
    "\n",
    "    if t > 1:\n",
    "        train_loss_dif = (train_loss_hist[-2] - train_loss_hist[-1]) * 100\n",
    "        val_loss_dif = (val_loss_hist[-2] - val_loss_hist[-1]) * 100\n",
    "        train_val_loss_dif = (train_loss_hist[-1] - val_loss_hist[-1]) * 100\n",
    "        print()\n",
    "        print(f\"Train Loss Difference: {train_loss_dif:>0.4f}\\t\\tVal Loss Difference: {val_loss_dif:>0.4f}\")\n",
    "        print(f\"Train Val Loss Difference: {train_val_loss_dif:>0.4f}\")\n",
    "        print()\n",
    "\n",
    "    got_new_loss = get_best_loss(val_loss_hist[-1], model)\n",
    "\n",
    "    if got_new_loss:\n",
    "        t_with_best_loss = t\n",
    "        best_loss = val_loss_hist[-1]\n",
    "    \n",
    "    t_since_best_loss = t - t_with_best_loss\n",
    "    \n",
    "    print(f\"Epoch with best loss: {t_with_best_loss}\\t\\tBest Loss: {best_loss:12f}\")\n",
    "    print(f\"Epochs Since Best Loss: {t_since_best_loss}\")\n",
    "\n",
    "    print(f\"Run Time: {round((time.time() - start), 2)}s\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    return t_with_best_loss, best_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training and Validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 0\n",
    "# t_with_best_loss = 0\n",
    "# best_loss = 0\n",
    "\n",
    "# # model.load_state_dict(torch.load(last_epoch_model_path))\n",
    "\n",
    "# while True:\n",
    "#     start = time.time()\n",
    "#     t = t + 1\n",
    "\n",
    "#     print(f\"Epoch {t}\\n-------------------------------\")\n",
    "\n",
    "#     train_and_eval(train_dataloader, optimizer, True, True)\n",
    "#     train_and_eval(val_dataloader, optimizer, False, True)\n",
    "#     t_with_best_loss, best_loss = print_metrics(start, t, t_with_best_loss, best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], dtype=torch.int64) tensor([8, 1, 8, 5]) tensor([0., 0., 0., 8.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([], dtype=torch.int64)\n",
      "target_pin: tensor([8, 1, 8, 5])\n",
      "pred_pin_other: tensor([0., 0., 0., 8.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([], dtype=torch.int64) tensor([9, 5, 5, 2]) tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([], dtype=torch.int64)\n",
      "target_pin: tensor([9, 5, 5, 2])\n",
      "pred_pin_other: tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([2]) tensor([2, 7, 2, 8]) tensor([2., 4., 2., 5.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([2])\n",
      "target_pin: tensor([2, 7, 2, 8])\n",
      "pred_pin_other: tensor([2., 4., 2., 5.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([], dtype=torch.int64) tensor([3, 5, 2, 6]) tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([], dtype=torch.int64)\n",
      "target_pin: tensor([3, 5, 2, 6])\n",
      "pred_pin_other: tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([3]) tensor([8, 1, 1, 1]) tensor([5., 1., 1., 1.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([3])\n",
      "target_pin: tensor([8, 1, 1, 1])\n",
      "pred_pin_other: tensor([5., 1., 1., 1.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1]) tensor([6, 3, 2, 7]) tensor([6., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1])\n",
      "target_pin: tensor([6, 3, 2, 7])\n",
      "pred_pin_other: tensor([6., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 1]) tensor([5, 6, 2, 5]) tensor([5., 6., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 1])\n",
      "target_pin: tensor([5, 6, 2, 5])\n",
      "pred_pin_other: tensor([5., 6., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 1, 1]) tensor([8, 5, 1, 4]) tensor([5., 5., 1., 4.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 1, 1])\n",
      "target_pin: tensor([8, 5, 1, 4])\n",
      "pred_pin_other: tensor([5., 5., 1., 4.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1]) tensor([9, 5, 0, 7]) tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1])\n",
      "target_pin: tensor([9, 5, 0, 7])\n",
      "pred_pin_other: tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([2]) tensor([2, 8, 2, 3]) tensor([2., 5., 2., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([2])\n",
      "target_pin: tensor([2, 8, 2, 3])\n",
      "pred_pin_other: tensor([2., 5., 2., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1]) tensor([6, 9, 9, 5]) tensor([6., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1])\n",
      "target_pin: tensor([6, 9, 9, 5])\n",
      "pred_pin_other: tensor([6., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1]) tensor([0, 9, 0, 5]) tensor([8., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1])\n",
      "target_pin: tensor([0, 9, 0, 5])\n",
      "pred_pin_other: tensor([8., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 2]) tensor([8, 7, 8, 5]) tensor([8., 4., 8., 5.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 2])\n",
      "target_pin: tensor([8, 7, 8, 5])\n",
      "pred_pin_other: tensor([8., 4., 8., 5.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1]) tensor([6, 8, 5, 6]) tensor([6., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1])\n",
      "target_pin: tensor([6, 8, 5, 6])\n",
      "pred_pin_other: tensor([6., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 1, 1]) tensor([1, 4, 3, 0]) tensor([1., 4., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 1, 1])\n",
      "target_pin: tensor([1, 4, 3, 0])\n",
      "pred_pin_other: tensor([1., 4., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 1]) tensor([2, 8, 9, 9]) tensor([2., 0., 0., 9.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 1])\n",
      "target_pin: tensor([2, 8, 9, 9])\n",
      "pred_pin_other: tensor([2., 0., 0., 9.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 1, 1, 1]) tensor([5, 2, 4, 8]) tensor([5., 2., 4., 8.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 1, 1, 1])\n",
      "target_pin: tensor([5, 2, 4, 8])\n",
      "pred_pin_other: tensor([5., 2., 4., 8.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([2, 1]) tensor([4, 0, 4, 5]) tensor([4., 8., 4., 5.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([2, 1])\n",
      "target_pin: tensor([4, 0, 4, 5])\n",
      "pred_pin_other: tensor([4., 8., 4., 5.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([], dtype=torch.int64) tensor([6, 6, 5, 7]) tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([], dtype=torch.int64)\n",
      "target_pin: tensor([6, 6, 5, 7])\n",
      "pred_pin_other: tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 1]) tensor([7, 0, 4, 0]) tensor([7., 8., 4., 8.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 1])\n",
      "target_pin: tensor([7, 0, 4, 0])\n",
      "pred_pin_other: tensor([7., 8., 4., 8.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([2]) tensor([3, 0, 0, 2]) tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([2])\n",
      "target_pin: tensor([3, 0, 0, 2])\n",
      "pred_pin_other: tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([], dtype=torch.int64) tensor([5, 6, 2, 1]) tensor([0., 0., 6., 2.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([], dtype=torch.int64)\n",
      "target_pin: tensor([5, 6, 2, 1])\n",
      "pred_pin_other: tensor([0., 0., 6., 2.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([], dtype=torch.int64) tensor([5, 1, 7, 1]) tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([], dtype=torch.int64)\n",
      "target_pin: tensor([5, 1, 7, 1])\n",
      "pred_pin_other: tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([2]) tensor([4, 4, 9, 5]) tensor([4., 4., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([2])\n",
      "target_pin: tensor([4, 4, 9, 5])\n",
      "pred_pin_other: tensor([4., 4., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 1]) tensor([5, 2, 8, 0]) tensor([5., 2., 5., 8.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 1])\n",
      "target_pin: tensor([5, 2, 8, 0])\n",
      "pred_pin_other: tensor([5., 2., 5., 8.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 1]) tensor([9, 6, 2, 0]) tensor([9., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 1])\n",
      "target_pin: tensor([9, 6, 2, 0])\n",
      "pred_pin_other: tensor([9., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([], dtype=torch.int64) tensor([6, 3, 5, 9]) tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([], dtype=torch.int64)\n",
      "target_pin: tensor([6, 3, 5, 9])\n",
      "pred_pin_other: tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([], dtype=torch.int64) tensor([7, 6, 5, 2]) tensor([4., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([], dtype=torch.int64)\n",
      "target_pin: tensor([7, 6, 5, 2])\n",
      "pred_pin_other: tensor([4., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 1, 1]) tensor([4, 1, 7, 3]) tensor([4., 1., 0., 3.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 1, 1])\n",
      "target_pin: tensor([4, 1, 7, 3])\n",
      "pred_pin_other: tensor([4., 1., 0., 3.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1]) tensor([5, 3, 6, 4]) tensor([5., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1])\n",
      "target_pin: tensor([5, 3, 6, 4])\n",
      "pred_pin_other: tensor([5., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 1]) tensor([7, 1, 0, 0]) tensor([7., 0., 0., 8.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 1])\n",
      "target_pin: tensor([7, 1, 0, 0])\n",
      "pred_pin_other: tensor([7., 0., 0., 8.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 1]) tensor([0, 2, 6, 4]) tensor([0., 0., 6., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 1])\n",
      "target_pin: tensor([0, 2, 6, 4])\n",
      "pred_pin_other: tensor([0., 0., 6., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([], dtype=torch.int64) tensor([0, 3, 2, 6]) tensor([8., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([], dtype=torch.int64)\n",
      "target_pin: tensor([0, 3, 2, 6])\n",
      "pred_pin_other: tensor([8., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([], dtype=torch.int64) tensor([3, 7, 8, 1]) tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([], dtype=torch.int64)\n",
      "target_pin: tensor([3, 7, 8, 1])\n",
      "pred_pin_other: tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1]) tensor([5, 6, 5, 8]) tensor([5., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1])\n",
      "target_pin: tensor([5, 6, 5, 8])\n",
      "pred_pin_other: tensor([5., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([], dtype=torch.int64) tensor([3, 3, 1, 9]) tensor([0., 0., 0., 1.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([], dtype=torch.int64)\n",
      "target_pin: tensor([3, 3, 1, 9])\n",
      "pred_pin_other: tensor([0., 0., 0., 1.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([], dtype=torch.int64) tensor([2, 7, 7, 2]) tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([], dtype=torch.int64)\n",
      "target_pin: tensor([2, 7, 7, 2])\n",
      "pred_pin_other: tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1]) tensor([6, 2, 0, 5]) tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1])\n",
      "target_pin: tensor([6, 2, 0, 5])\n",
      "pred_pin_other: tensor([0., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 1]) tensor([4, 8, 9, 3]) tensor([4., 8., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 1])\n",
      "target_pin: tensor([4, 8, 9, 3])\n",
      "pred_pin_other: tensor([4., 8., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([3, 1]) tensor([4, 1, 1, 1]) tensor([4., 1., 1., 1.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([3, 1])\n",
      "target_pin: tensor([4, 1, 1, 1])\n",
      "pred_pin_other: tensor([4., 1., 1., 1.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([2, 1, 1]) tensor([4, 6, 2, 2]) tensor([4., 6., 2., 2.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([2, 1, 1])\n",
      "target_pin: tensor([4, 6, 2, 2])\n",
      "pred_pin_other: tensor([4., 6., 2., 2.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1]) tensor([2, 6, 4, 6]) tensor([2., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1])\n",
      "target_pin: tensor([2, 6, 4, 6])\n",
      "pred_pin_other: tensor([2., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 2]) tensor([0, 1, 4, 4]) tensor([8., 1., 4., 4.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 2])\n",
      "target_pin: tensor([0, 1, 4, 4])\n",
      "pred_pin_other: tensor([8., 1., 4., 4.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([2, 1]) tensor([9, 0, 0, 3]) tensor([9., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([2, 1])\n",
      "target_pin: tensor([9, 0, 0, 3])\n",
      "pred_pin_other: tensor([9., 0., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1, 1, 1]) tensor([7, 9, 0, 4]) tensor([7., 9., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1, 1, 1])\n",
      "target_pin: tensor([7, 9, 0, 4])\n",
      "pred_pin_other: tensor([7., 9., 0., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([], dtype=torch.int64) tensor([5, 3, 4, 5]) tensor([0., 0., 3., 0.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([], dtype=torch.int64)\n",
      "target_pin: tensor([5, 3, 4, 5])\n",
      "pred_pin_other: tensor([0., 0., 3., 0.])\n",
      "\n",
      "\n",
      "\n",
      "tensor([1]) tensor([3, 3, 7, 5]) tensor([3., 0., 3., 7.])\n",
      "\n",
      "\n",
      "\n",
      "Counts: tensor([1])\n",
      "target_pin: tensor([3, 3, 7, 5])\n",
      "pred_pin_other: tensor([3., 0., 3., 7.])\n",
      "\n",
      "\n",
      "\n",
      "0.425531914893617\n"
     ]
    }
   ],
   "source": [
    "src_dir = \"./PinDataCalibrateBack/\"\n",
    "\n",
    "fps = 100\n",
    "conf = 0.3\n",
    "\n",
    "number_locations = torch.zeros((6,6))\n",
    "\n",
    "number_locations[0,3] = 0\n",
    "\n",
    "number_locations[3,4] = 1\n",
    "number_locations[3,3] = 2\n",
    "number_locations[3,2] = 3\n",
    "\n",
    "number_locations[2,4] = 4\n",
    "number_locations[2,3] = 5\n",
    "number_locations[2,2] = 6\n",
    "\n",
    "number_locations[1,4] = 7\n",
    "number_locations[1,3] = 8\n",
    "number_locations[1,2] = 9\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "file_names = get_file_names(src_dir)\n",
    "\n",
    "correct, size = 0, 0\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for src in file_names:\n",
    "        file_name_split = src.split(\"_\")\n",
    "        count = 0\n",
    "\n",
    "        if file_name_split[0] != \"Front\":\n",
    "            continue\n",
    "\n",
    "        target_pin = file_name_split[1]\n",
    "        target_pin = [int(x) for x in target_pin]\n",
    "\n",
    "        pred_pin_other = []\n",
    "        pred_pin_idx = 0\n",
    "\n",
    "        max_x = 0\n",
    "        max_y = 0\n",
    "\n",
    "        gathering_pins = False\n",
    "\n",
    "        vidcap = cv2.VideoCapture(join(src_dir, src))\n",
    "        success,image = vidcap.read()\n",
    "\n",
    "        if not success or image is None:\n",
    "            print(\"ERROR\", src)\n",
    "            continue\n",
    "\n",
    "\n",
    "        while success:\n",
    "            vidcap.set(cv2.CAP_PROP_POS_MSEC,(count*fps))\n",
    "\n",
    "            success,image = vidcap.read()\n",
    "\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            if len(pred_pin_other) >= 4:\n",
    "                break\n",
    "\n",
    "            X = transform_resize(image=image)[\"image\"]\n",
    "            X = transform_normalize(image=X)[\"image\"]\n",
    "            X = torch.tensor(X, device=device).permute([2,0,1]).unsqueeze(0)\n",
    "\n",
    "            pin_prob = model(X)\n",
    "\n",
    "            pred_pin = torch.argmax(pin_prob, 2).cpu().squeeze().tolist()\n",
    "\n",
    "            pred_pin_x = pred_pin[0]\n",
    "            pred_pin_y = pred_pin[1]\n",
    "\n",
    "            pin_prob = pin_prob.cpu().tolist()\n",
    "            pin_prob = pin_prob[0]\n",
    "\n",
    "            pin_x_prob = pin_prob[0][pred_pin_x]\n",
    "            pin_y_prob = pin_prob[1][pred_pin_y]\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            if pred_pin_x >= 0 and pred_pin_y <= 1:\n",
    "            \n",
    "                if gathering_pins == True:\n",
    "                    num = number_locations[max_x, max_y]\n",
    "                    max_x = 0\n",
    "                    max_y = 0\n",
    "                    pred_pin_other.append(num)\n",
    "\n",
    "                gathering_pins = not gathering_pins\n",
    "\n",
    "            if pin_x_prob >= conf and pin_y_prob >= conf and gathering_pins:\n",
    "                \n",
    "                if pred_pin_x > max_x:\n",
    "                    max_x = pred_pin_x\n",
    "                \n",
    "                if pred_pin_y > max_y:\n",
    "                    max_y = pred_pin_y\n",
    "\n",
    "        vidcap.release()\n",
    "\n",
    "\n",
    "        target_pin = torch.tensor(target_pin)\n",
    "\n",
    "        pred_pin_other = torch.tensor(pred_pin_other)\n",
    "\n",
    "        if pred_pin_other.shape[0] < 4:\n",
    "            # pred_pin_other = torch.vstack([pred_pin_other, torch.tensor([0])])\n",
    "            continue\n",
    "\n",
    "        values, counts = torch.unique(target_pin[target_pin == pred_pin_other], return_counts=True)\n",
    "\n",
    "        print(counts, target_pin, pred_pin_other)\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        print(f\"Counts: {counts}\")\n",
    "        print(f\"target_pin: {target_pin}\")\n",
    "        print(f\"pred_pin_other: {pred_pin_other}\")\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "        corrects, sizes = get_corrects_and_size(target_pin, pred_pin_other)\n",
    "\n",
    "        correct += corrects\n",
    "        size += sizes\n",
    "\n",
    "        \n",
    "print(correct / size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# model.eval()\n",
    "# conf = 0.3\n",
    "\n",
    "# with torch.no_grad():\n",
    "\n",
    "#     max_x = 0\n",
    "#     max_y = 0\n",
    "#     count = 0\n",
    "\n",
    "#     vidcap = cv2.VideoCapture(\"/home/tyler/Documents/Data/PinData/PinDataTestv2/Front_8152_103fab40-ecac-4ef0-8884-bac83ffd9328.mp4\")\n",
    "#     os.makedirs(\"./tests/\", exist_ok=True)\n",
    "#     success,image = vidcap.read()\n",
    "\n",
    "#     while success:\n",
    "#         vidcap.set(cv2.CAP_PROP_POS_MSEC,(count*100))\n",
    "#         success,image = vidcap.read()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#         if not success:\n",
    "#             break\n",
    "        \n",
    "#         image = image[200:400, 200:400, :]\n",
    "\n",
    "#         X = transform_resize(image=image)[\"image\"]\n",
    "#         X = transform_normalize(image=X)[\"image\"]\n",
    "#         X = torch.tensor(X, device=device).permute([2,0,1]).unsqueeze(0)\n",
    "\n",
    "#         pred = model(X)\n",
    "\n",
    "#         pred_index = torch.argmax(pred, 2).cpu().squeeze().tolist()\n",
    "\n",
    "#         pred = pred.cpu().tolist()\n",
    "#         pred = pred[0]\n",
    "\n",
    "#         pred_1 = pred[0][pred_index[0]]\n",
    "#         pred_2 = pred[1][pred_index[1]]\n",
    "        \n",
    "#         if pred_1 >= conf and pred_2 >= conf:\n",
    "            \n",
    "#             if pred_index[0] > max_x:\n",
    "#                 max_x = pred_index[0]\n",
    "            \n",
    "#             if pred_index[1] > max_y:\n",
    "#                 max_y = pred_index[1]\n",
    "\n",
    "#             add_grid_lines(image)\n",
    "\n",
    "#             cv2.imwrite(f\"./tests/{count}{pred_index}.jpeg\", image)\n",
    "\n",
    "\n",
    "\n",
    "#         count += 1\n",
    "\n",
    "       \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "#     print(max_x, \"max_x\", max_y, \"max_y\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#     # if pred_1 >= 0.6 and pred_2 >= 0.6:\n",
    "#     #     text = f\"\\n\\nConfident\\n\\nFile: {file_name}\\nPred: {pred}\\ny: {y}\\npred_idx: {pred_index} y_idx: {y_index}\\n\\n\"\n",
    "#     #     print(text)\n",
    "#     #     count += 1\n",
    "\n",
    "#     # elif pred_2 >= 0.7:\n",
    "#     #     text = f\"\\n\\nConfident\\n\\nFile: {file_name}\\nPred: {pred}\\ny: {y}\\npred_idx: {pred_index} y_idx: {y_index}\\n\\n\"\n",
    "#     #     print(text)\n",
    "\n",
    "#     # else:\n",
    "#     #     text = f\"\\n\\n!NOT! Confident\\n\\nFile: {file_name}\\nPred: {pred}\\ny: {y}\\npred_idx: {pred_index} y_idx: {y_index}\\n\\n\"\n",
    "#     #     print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
